{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a80fa0a-2d12-474a-8eb6-e18c28a4c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "from scipy.stats import friedmanchisquare\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import friedmanchisquare\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import wilcoxon\n",
    "from itertools import combinations\n",
    "import openpyxl\n",
    "import scienceplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7505da3c-edf3-417e-8337-e80b2baca57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Questionairs (in flight)\n",
    "# se base foler\n",
    "\n",
    "# Define the base folder path\n",
    "#base_folder = r'C:\\Users\\ejnar\\Desktop\\Special sync\\Special'\n",
    "base_folder = r'C:\\Users\\ejnar\\OneDrive\\DTU\\speciale_projekt\\Spirometer fra test'\n",
    "# Define the path to the Excel file\n",
    "excel_file_path1 = os.path.join(base_folder, 'Full_spyro_output.xlsx')\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel(excel_file_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a20aaba-cc09-4542-9c3b-2d261606ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the columns you want to keep\n",
    "columns_to_keep = ['SESSION_DATE_TIME','SUBJECT_ID','filter']\n",
    "\n",
    "# Keep only the specified columns\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7e5e9f-3103-44e3-9367-4f68283c57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine Medical_Test based on time\n",
    "def assign_medical_test(session_time):\n",
    "    time = session_time.time()\n",
    "    if pd.Timestamp('09:00').time() <= time <= pd.Timestamp('10:30').time():\n",
    "        return 1\n",
    "    elif pd.Timestamp('14:30').time() <= time <= pd.Timestamp('17:00').time():\n",
    "        return 2\n",
    "    elif pd.Timestamp('18:00').time() <= time <= pd.Timestamp('21:00').time():\n",
    "        return 3\n",
    "    else:\n",
    "        return None  # You can use 0 or another value for times outside these ranges\n",
    "\n",
    "# Apply the function to create Medical_Test column\n",
    "df['Medical_Test'] = df['SESSION_DATE_TIME'].apply(assign_medical_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8738230f-4d3c-4cff-aa89-af18f8db643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "df['SESSION_DATE_TIME'] = pd.to_datetime(df['SESSION_DATE_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Sort the DataFrame by the SESSION_DATE_TIME column\n",
    "df = df.sort_values(by='SESSION_DATE_TIME')\n",
    "\n",
    "#reset the index after sorting\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fddc1c4-a9ea-4fef-84d7-7b3efbe29bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base folder where the Vision test data is located\n",
    "base_folder2 = r'C:\\Users\\ejnar\\OneDrive\\DTU\\speciale_projekt\\Vision\\Vision test'\n",
    "\n",
    "# List of days to exclude\n",
    "excluded_days = [\n",
    "    '2024-09-07', '2024-09-08', '2024-09-09', '2024-09-14', '2024-09-15',\n",
    "    '2024-09-16', '2024-09-21', '2024-09-22', '2024-09-23'\n",
    "]\n",
    "\n",
    "# Initialize DataFrames to store the data\n",
    "df_landoltC = pd.DataFrame(columns=['Acuity Landolt C Score\tvalue'])\n",
    "reaction_times = []\n",
    "correct_answers = []\n",
    "min_values_column_5 = []\n",
    "\n",
    "# Iterate through all the days\n",
    "for day in pd.date_range('2024-09-03', '2024-09-27').strftime('%Y-%m-%d'):\n",
    "    # Skip excluded days\n",
    "    if day in excluded_days:\n",
    "        continue\n",
    "    \n",
    "    # Iterate through the three medical tests\n",
    "    for test_num in range(1, 4):\n",
    "        # Iterate through all 17 test files for each medical test\n",
    "        for test_file_num in range(1, 18):  # 1 to 17 for each test\n",
    "            sub_folder = day\n",
    "            sub_sub_folder = f'Medical test {test_num}'\n",
    "            \n",
    "            # Define the file name based\n",
    "            file_name = f'{day[5:7]}{day[8:10]}MT{test_num}_{test_file_num}.txt'  # Example: 0903MT1_1.txt\n",
    "            \n",
    "            # Build the file path\n",
    "            excel_file_path1 = os.path.join(base_folder2, sub_folder, sub_sub_folder, file_name)\n",
    "            \n",
    "            # Check if the file exists\n",
    "            if os.path.exists(excel_file_path1):\n",
    "                # Load the file into a DataFrame\n",
    "                df2 = pd.read_csv(excel_file_path1, sep='\\t', encoding='utf-16')\n",
    "                \n",
    "                # Extract the specific data from the 14th column\n",
    "                if len(df2.columns) > 13:\n",
    "                    landoltC_column_name = df2.columns[13]\n",
    "                    df_landoltC.at[len(df_landoltC), 'Acuity Landolt C Score\tvalue'] = landoltC_column_name\n",
    "                \n",
    "                # Reaction time calculation\n",
    "                if \".\" in df2.columns:\n",
    "                    df2[\".\"] = pd.to_numeric(df2[\".\"], errors='coerce')\n",
    "                    reaction_time = df2[\".\"].iloc[2:].sum()\n",
    "                    reaction_times.append(reaction_time)\n",
    "                \n",
    "                # Count correct answers\n",
    "                if \"decimalMark\" in df2.columns:\n",
    "                    df2[\"decimalMark\"] = df2[\"decimalMark\"].apply(lambda x: str(x).strip().lower())\n",
    "                    count_true = df2[\"decimalMark\"].iloc[1:].apply(lambda x: x == \"true\").sum()\n",
    "                    correct_answers.append(count_true)\n",
    "                \n",
    "                # Minimum value in column\n",
    "                if \"5\" in df2.columns and \"decimalMark\" in df2.columns:\n",
    "                    df2[\"5\"] = pd.to_numeric(df2[\"5\"], errors=\"coerce\")\n",
    "                    true_rows = df2[df2[\"decimalMark\"] == \"true\"]\n",
    "                    if not true_rows.empty:\n",
    "                        min_value = true_rows[\"5\"].min()\n",
    "                        min_values_column_5.append(min_value)\n",
    "                    else:\n",
    "                        min_values_column_5.append(None)\n",
    "            else:\n",
    "                print(f\"File not found: {excel_file_path1}\")\n",
    "\n",
    "# Convert the collected results\n",
    "df_results = pd.DataFrame({\n",
    "    'Reaction Time': reaction_times,\n",
    "    'Correct Answers': correct_answers,\n",
    "    'Min Correct value': min_values_column_5\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2724b5e5-23f6-485e-ab37-75873219d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_results, left_index=True, right_index=True, how='outer')\n",
    "#muligvis fiks senere\n",
    "df = pd.merge(df, df_landoltC, left_index=True, right_index=True, how='outer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af167745-091e-4a23-b8ef-2a068daa0467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column in the DataFrame\n",
    "df = df.rename(columns={\"Acuity Landolt C Score\\tvalue\": \"Acuity Landolt C Score\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecfd6c35-85f4-4562-b7b0-5c3ca0ae00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exstra filter \n",
    "participants_to_keep = [1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, \n",
    "                        30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, \n",
    "                        57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69]\n",
    "\n",
    "# Filter the DataFrame\n",
    "df = df[df['SUBJECT_ID'].isin(participants_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98488d4-dbce-45f8-9cfd-1b20faceeb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named `df`\n",
    "df = df[df['filter'] != 'error']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dafadf9-cef3-48f9-a9b1-a78b3baca447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure SESSION_DATE_TIME is in datetime format\n",
    "df['SESSION_DATE_TIME'] = pd.to_datetime(df['SESSION_DATE_TIME'])\n",
    "\n",
    "# Extract day and time as separate columns\n",
    "df['SESSION_DATE'] = df['SESSION_DATE_TIME'].dt.date  # Extract only the date part\n",
    "df['SESSION_TIME'] = df['SESSION_DATE_TIME'].dt.time  # Extract only the time part\n",
    "\n",
    "# Sort by day first, then by time\n",
    "df = df.sort_values(by=['SESSION_DATE', 'SESSION_TIME'], ascending=True)\n",
    "\n",
    "# Drop temporary columns\n",
    "df.drop(columns=['SESSION_DATE', 'SESSION_TIME'], inplace=True)\n",
    "\n",
    "# Reset index if needed\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a62ca9-6c3c-47ed-ab3b-0440ca99f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "df['Acuity Landolt C Score'] = pd.to_numeric(df['Acuity Landolt C Score'], errors='coerce')\n",
    "\n",
    "# Rename the column with the tab character\n",
    "df.rename(columns={'Acuity Landolt C Score': 'LogMar value'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98dc0406-2873-489e-9e9e-d07f9aace239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Reaction Time from ms to s\n",
    "df['Reaction Time (S)'] = df['Reaction Time'] / 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15fc3201-b201-428b-8697-59bad3f779ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename collums\n",
    "df.rename(columns={'Reaction Time (S)': 'Completion Time'}, inplace=True)\n",
    "df.rename(columns={'Correct Answers': 'Correct Answers'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218e480a-05ff-4f33-bfb6-e31c20ab3582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divided into filter\n",
    "dfHepa7 = df[df['filter'] == 'A']\n",
    "dfAPSU = df[df['filter'] == 'B']\n",
    "dfHepa5 = df[df['filter'] == 'C']\n",
    "dfAPSN = df[df['filter'] == 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76ec216d-e237-4a4f-af26-8431006541e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot creation\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"Replace invalid characters in a filename with underscores.\"\"\"\n",
    "    return re.sub(r'[<>:\"/\\\\|?*\\t]', '_', name)\n",
    "\n",
    "\n",
    "def create_combined_boxplots(dataframes, labels, columns_to_plot, name_suffix=\"\", nametag=\"\", y_min=0, y_max=102):\n",
    "    \"\"\"Create combined box plots for specified columns in a list of DataFrames.\"\"\"\n",
    "    # Get the current directory where the script is placed\n",
    "    current_directory = os.getcwd()\n",
    "    output_folder = os.path.join(current_directory, \"figur\")\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Apply the 'science' style and 'no-latex'\n",
    "    plt.style.use(['science', 'no-latex'])\n",
    "\n",
    "    # Define the color palette to match the second code\n",
    "    colors = ['#77AADD', '#99DDFF', '#44BB99', '#BBCC33']\n",
    "    sns.set_palette(colors)\n",
    "\n",
    "    # Assuming all DataFrames have the same 'Medical-Test' values\n",
    "    medical_tests = dataframes[0]['Medical_Test'].unique()\n",
    "\n",
    "    # Define custom x-tick labels\n",
    "    custom_labels = [\"MT1\", \"MT2\", \"MT3\"]\n",
    "\n",
    "    # Loop through the specified columns in the DataFrames\n",
    "    for column in columns_to_plot:\n",
    "        if column in dataframes[0].columns and pd.api.types.is_numeric_dtype(dataframes[0][column]):  # Check if column is numeric\n",
    "            plt.figure(figsize=(10, 7))  # Match figure size\n",
    "\n",
    "            # Combine data for seaborn boxplot\n",
    "            combined_data = pd.concat([\n",
    "                dataframe.assign(Dataset=labels[i]) \n",
    "                for i, dataframe in enumerate(dataframes)\n",
    "            ])\n",
    "\n",
    "            # Create the box plot\n",
    "            sns.boxplot(\n",
    "                x='Medical_Test', y=column, hue='Dataset', data=combined_data,\n",
    "                palette=colors, dodge=True\n",
    "            )\n",
    "\n",
    "            # Add titles and labels\n",
    "            plt.title(f\"{column} - {nametag}\",\n",
    "                  fontsize=20, pad=15)\n",
    "            plt.xlabel('Medical Test', fontsize=18)\n",
    "            plt.ylabel('Number of Correct Responses [-]', fontsize=18)\n",
    "\n",
    "            # Set y-axis limits\n",
    "            plt.ylim(y_min, y_max)\n",
    "\n",
    "            # Set x-ticks and their labels\n",
    "            plt.xticks(ticks=range(len(custom_labels)), labels=custom_labels, fontsize=16)\n",
    "            plt.yticks(fontsize=16)\n",
    "\n",
    "            # Add legend styled like the second code\n",
    "            plt.legend(\n",
    "                title=\"Conditions\", title_fontsize=16, fontsize=14,\n",
    "                loc='center left', bbox_to_anchor=(1, 0.5), frameon=False\n",
    "            )\n",
    "\n",
    "            # Add grid lines for y-axis\n",
    "            plt.grid(visible=True, linestyle='--', linewidth=0.5, alpha=0.75, axis='y')\n",
    "\n",
    "            # Adjust layout for better spacing\n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save the plot\n",
    "            plot_filename = f\"{sanitize_filename(column)}_{sanitize_filename(name_suffix)}.png\"\n",
    "            plt.savefig(os.path.join(output_folder, plot_filename), bbox_inches='tight')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d6119c9-106a-4c77-9926-1b46bd18ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f√∏rst plot som er raw data \n",
    "dataframesRaw = [dfHepa7, dfHepa5,dfAPSN, dfAPSU]  \n",
    "\n",
    "\n",
    "labels = ['HEPA 7', 'HEPA 5', 'APS N', 'APS U']  # Labels for each DataFrame\n",
    "\n",
    "output_folder = base_folder\n",
    "\n",
    "name_suffix = 'All'\n",
    "nametag = name_suffix\n",
    "columns_to_plot1 = ['Completion Time']\n",
    "columns_to_plot2 = ['Percentage Correct']\n",
    "columns_to_plot3 = ['Correct Answers']\n",
    "columns_to_plot4 = ['LogMar value']\n",
    "columns_to_plot5 = ['Min Correct value']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the combined boxplots with a name suffix and custom colors\n",
    "create_combined_boxplots(dataframesRaw, labels,columns_to_plot1, name_suffix=name_suffix,nametag=nametag, y_min=0, y_max=100)\n",
    "create_combined_boxplots(dataframesRaw, labels,columns_to_plot2, name_suffix=name_suffix,nametag=nametag, y_min=0, y_max=100)\n",
    "create_combined_boxplots(dataframesRaw, labels,columns_to_plot3, name_suffix=name_suffix,nametag=nametag, y_min=0, y_max=18)\n",
    "create_combined_boxplots(dataframesRaw, labels,columns_to_plot4, name_suffix=name_suffix,nametag=nametag, y_min=-1, y_max=1)\n",
    "create_combined_boxplots(dataframesRaw, labels,columns_to_plot5, name_suffix=name_suffix,nametag=nametag, y_min=-1, y_max=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4eed555-9c86-473a-a026-f6e51e28d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejnar\\AppData\\Local\\Temp\\ipykernel_9552\\4019445914.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  friedman_results_df = pd.concat([friedman_results_df, temp_df], ignore_index=True)\n",
      "C:\\Users\\ejnar\\AppData\\Local\\Temp\\ipykernel_9552\\4019445914.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  friedman_results_df = pd.concat([friedman_results_df, temp_df], ignore_index=True)\n",
      "C:\\Users\\ejnar\\AppData\\Local\\Temp\\ipykernel_9552\\4019445914.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  friedman_results_df = pd.concat([friedman_results_df, temp_df], ignore_index=True)\n",
      "C:\\Users\\ejnar\\AppData\\Local\\Temp\\ipykernel_9552\\4019445914.py:48: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  friedman_results_df = pd.concat([friedman_results_df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman and Wilcoxon test results saved to Friedman-Wilcoxon-by-Questinair-Vision-All.xlsx.\n"
     ]
    }
   ],
   "source": [
    "# Define output file path\n",
    "# freidman willcox by time\n",
    "output_path = f'Friedman-Wilcoxon-by-Questinair-Vision-{name_suffix}.xlsx'\n",
    "\n",
    "# DataFrames for each dataset\n",
    "dataframes = {\n",
    "    \"Hepa 7\": dfHepa7,\n",
    "    \"Hepa 5\": dfHepa5,\n",
    "    \"APSU\": dfAPSU,\n",
    "    \"APSN\": dfAPSN\n",
    "}\n",
    "\n",
    "# Specify columns not to test\n",
    "columns_not_to_test = ['SUBJECT_ID', 'Medical_Test','SESSION_DATE_TIME','filter','Reaction Time']\n",
    "\n",
    "# Alpha significance level\n",
    "alpha = 0.1\n",
    "\n",
    "# Initialize an Excel writer\n",
    "with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "    for dataset_name, df in dataframes.items():\n",
    "        # Determine columns to test by excluding the specified ones\n",
    "        columns_to_test = df.columns.difference(columns_not_to_test).tolist()\n",
    "\n",
    "        # Initialize DataFrames to store result\n",
    "        friedman_results_df = pd.DataFrame(columns=[\"Column\", \"Statistic\", \"p-value\", \"Alpha\", \"Significant\"])\n",
    "        wilcoxon_results_list = []\n",
    "\n",
    "        # Loop through each column\n",
    "        for col in columns_to_test:\n",
    "            # Filter out data for each\n",
    "            medical_test_groups = [df[df[\"Medical_Test\"] == i][col].dropna().values for i in range(1, 4)]\n",
    "            \n",
    "            # Perform the Friedman test\n",
    "            friedman_stat, friedman_p = friedmanchisquare(*medical_test_groups)\n",
    "            \n",
    "            # Determine if the result is significant\n",
    "            is_significant = 1 if friedman_p < alpha else 0\n",
    "            \n",
    "            # Append Friedman test result\n",
    "            temp_df = pd.DataFrame({\n",
    "                \"Column\": [col],\n",
    "                \"Statistic\": [friedman_stat],\n",
    "                \"p-value\": [friedman_p],\n",
    "                \"Alpha\": [alpha],\n",
    "                \"Significant\": [is_significant]\n",
    "            })\n",
    "            friedman_results_df = pd.concat([friedman_results_df, temp_df], ignore_index=True)\n",
    "\n",
    "            # If significant\n",
    "            if is_significant:\n",
    "                # Get all pairs of Medical_Test values\n",
    "                pairs = combinations(range(1, 4), 2)\n",
    "                for (i, j) in pairs:\n",
    "                    # Get data for each pair\n",
    "                    group1 = df[df[\"Medical_Test\"] == i][col].dropna().values\n",
    "                    group2 = df[df[\"Medical_Test\"] == j][col].dropna().values\n",
    "                    \n",
    "                    # Ensure both groups have data for the Wilcoxon test\n",
    "                    if len(group1) > 0 and len(group2) > 0:\n",
    "                        wilcox_stat, wilcox_p = wilcoxon(group1, group2)\n",
    "                        wilcox_significant = 1 if wilcox_p < alpha else 0  \n",
    "                        \n",
    "                        # Append results to the Wilcoxon results list\n",
    "                        wilcoxon_results_list.append({\n",
    "                            \"Column\": col,\n",
    "                            \"Pair\": f\"{i}-{j}\",\n",
    "                            \"Statistic\": wilcox_stat,\n",
    "                            \"p-value\": wilcox_p,\n",
    "                            \"Alpha\": alpha,\n",
    "                            \"Significant\": wilcox_significant\n",
    "                        })\n",
    "\n",
    "        # Save results for the current dataset in separate sheets\n",
    "        friedman_results_df.to_excel(writer, sheet_name=f\"{dataset_name} Friedman Results\", index=False)\n",
    "        \n",
    "        if wilcoxon_results_list:\n",
    "            wilcoxon_df = pd.DataFrame(wilcoxon_results_list)\n",
    "            wilcoxon_df.to_excel(writer, sheet_name=f\"{dataset_name} Wilcoxon Results\", index=False)\n",
    "\n",
    "print(f\"Friedman and Wilcoxon test results saved to {output_path}.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "456adc31-20d0-4ece-9149-78d5ed6defa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friedman and Wilcoxon test results saved to Friedman-Wilcoxon-by-Filter-Vision-All.xlsx.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejnar\\AppData\\Local\\Temp\\ipykernel_9552\\3540842675.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  friedman_results_df = pd.concat([\n",
      "C:\\Users\\ejnar\\AppData\\Local\\Temp\\ipykernel_9552\\3540842675.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  friedman_results_df = pd.concat([\n",
      "C:\\Users\\ejnar\\AppData\\Local\\Temp\\ipykernel_9552\\3540842675.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  friedman_results_df = pd.concat([\n"
     ]
    }
   ],
   "source": [
    "# Define output file path\n",
    "# freidman willcox by conditions\n",
    "output_path = f'Friedman-Wilcoxon-by-Filter-Vision-{name_suffix}.xlsx'\n",
    "\n",
    "# DataFrames for each dataset\n",
    "dataframes = {\n",
    "    \"Hepa 7\": dfHepa7,\n",
    "    \"Hepa 5\": dfHepa5,\n",
    "    \"APSU\": dfAPSU,\n",
    "    \"APSN\": dfAPSN\n",
    "}\n",
    "\n",
    "\n",
    "columns_not_to_test = ['SUBJECT_ID', 'Medical_Test', 'SESSION_DATE_TIME', 'filter','Reaction Time']\n",
    "\n",
    "# Alpha significance level\n",
    "alpha = 0.1\n",
    "\n",
    "# Initialize an Excel writer\n",
    "with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "    # Loop through each Medical_Test value\n",
    "    for medical_test in [1, 2, 3]:\n",
    "        # Create a new DataFrame for Friedman result\n",
    "        friedman_results_df = pd.DataFrame(columns=[\"Column\", \"Statistic\", \"p-value\", \"Alpha\", \"Significant\"])\n",
    "        wilcoxon_results_list = []  \n",
    "\n",
    "        # Determine columns to test\n",
    "        columns_to_test = dataframes[\"Hepa 7\"].columns.difference(columns_not_to_test).tolist()\n",
    "\n",
    "        # Loop through each column\n",
    "        for col in columns_to_test:\n",
    "            # Collect data across datasets for the current column and Medical_Test\n",
    "            data_groups = [\n",
    "                dataframes[name][dataframes[name][\"Medical_Test\"] == medical_test][col].dropna().values\n",
    "                for name in [\"Hepa 7\", \"Hepa 5\", \"APSU\", \"APSN\"]\n",
    "            ]\n",
    "\n",
    "            # Perform the Friedman test\n",
    "            friedman_stat, friedman_p = friedmanchisquare(*data_groups)\n",
    "\n",
    "            # Determine if the result is significant\n",
    "            is_significant = 1 if friedman_p < alpha else 0\n",
    "\n",
    "            # Append Friedman test results\n",
    "            friedman_results_df = pd.concat([\n",
    "                friedman_results_df,\n",
    "                pd.DataFrame({\n",
    "                    \"Column\": [col],\n",
    "                    \"Statistic\": [friedman_stat],\n",
    "                    \"p-value\": [friedman_p],\n",
    "                    \"Alpha\": [alpha],\n",
    "                    \"Significant\": [is_significant]\n",
    "                })\n",
    "            ], ignore_index=True)\n",
    "\n",
    "            # If significant\n",
    "            if is_significant:\n",
    "                pairs = combinations([\"Hepa 7\", \"Hepa 5\", \"APSU\", \"APSN\"], 2)\n",
    "                for (name1, name2) in pairs:\n",
    "                    group1 = dataframes[name1][dataframes[name1][\"Medical_Test\"] == medical_test][col].dropna().values\n",
    "                    group2 = dataframes[name2][dataframes[name2][\"Medical_Test\"] == medical_test][col].dropna().values\n",
    "\n",
    "                    # Ensure both groups have data\n",
    "                    if len(group1) > 0 and len(group2) > 0:\n",
    "                        wilcox_stat, wilcox_p = wilcoxon(group1, group2)\n",
    "                        wilcox_significant = 1 if wilcox_p < alpha else 0\n",
    "\n",
    "                        # Append Wilcoxon results\n",
    "                        wilcoxon_results_list.append({\n",
    "                            \"Column\": col,\n",
    "                            \"Pair\": f\"{name1} vs {name2}\",\n",
    "                            \"Statistic\": wilcox_stat,\n",
    "                            \"p-value\": wilcox_p,\n",
    "                            \"Alpha\": alpha,\n",
    "                            \"Significant\": wilcox_significant\n",
    "                        })\n",
    "\n",
    "        # Save results \n",
    "        friedman_results_df.to_excel(writer, sheet_name=f\"Medical {medical_test} Friedman Results\", index=False)\n",
    "\n",
    "        if wilcoxon_results_list:\n",
    "            wilcoxon_df = pd.DataFrame(wilcoxon_results_list)\n",
    "            wilcoxon_df.to_excel(writer, sheet_name=f\"Medical {medical_test} Wilcoxon Results\", index=False)\n",
    "\n",
    "print(f\"Friedman and Wilcoxon test results saved to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36f1bf68-9ebc-4138-b022-950cad1e29f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames saved to C:\\Users\\ejnar\\OneDrive\\DTU\\speciale_projekt\\Vision\\Vision_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define the filename\n",
    "#Save Dataframe\n",
    "filename = \"Vision_output.xlsx\"\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "file_path = os.path.join(current_dir, filename)\n",
    "\n",
    "# Initialize an Excel writer\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    # Loop through each dataset and save it to a separate sheet\n",
    "    for dataset_name, df in dataframes.items():\n",
    "        # Save each DataFrame to its corresponding sheet\n",
    "        df.to_excel(writer, sheet_name=dataset_name, index=False)\n",
    "\n",
    "print(f\"DataFrames saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f271661-b5d3-4caa-b852-52c2bed53053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
